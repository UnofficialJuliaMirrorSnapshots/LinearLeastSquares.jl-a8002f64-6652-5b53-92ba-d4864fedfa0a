<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>LineaLeastSquares.jl Examples &mdash; LLS 0.1 documentation</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="LLS 0.1 documentation" href="index.html" />
    <link rel="next" title="Credits" href="credits.html" />
    <link rel="prev" title="LinearLeastSquares.jl Tutorial" href="julia_tutorial.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="credits.html" title="Credits"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="julia_tutorial.html" title="LinearLeastSquares.jl Tutorial"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">LLS 0.1 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="linealeastsquares-jl-examples">
<h1>LineaLeastSquares.jl Examples<a class="headerlink" href="#linealeastsquares-jl-examples" title="Permalink to this headline">¶</a></h1>
<p>This tutorial showcases LinearLeastSquares.jl through a few involved examples of linearly
constrained least squares problems. We&#8217;ll refer to LinearLeastSquares.jl as &#8220;LLS&#8221;
throughout.
The plots generated by the following examples use the Gadfly package.
The documentation on how to use Gadfly can be found <a class="reference external" href="http://gadflyjl.org/">here</a>,
but by no means is it necessary to read unless you would like to create plots for yourself.
To install Gadfly, run the following command in a Julia shell</p>
<div class="highlight-none"><div class="highlight"><pre>Pkg.add(&quot;Gadfly&quot;)
</pre></div>
</div>
<p>Some of the examples will also use data files, which can all be found <a class="reference external" href="https://github.com/davidlizeng/LinearLeastSquares.jl/tree/master/examples/">here</a>.</p>
<div class="section" id="regression">
<h2>Regression<a class="headerlink" href="#regression" title="Permalink to this headline">¶</a></h2>
<p>Regression is the problem of trying to fit a function to some data.
In this example, we will frame some simple regression problems as
unconstrained least squares problems for LLS to solve.</p>
<p>We are given n points, represented by two n-by-1 vectors, <tt class="docutils literal"><span class="pre">x_data</span></tt> and <tt class="docutils literal"><span class="pre">y_data</span></tt>. The x and y coordinates of the i-th point are given by the i-th entries of <tt class="docutils literal"><span class="pre">x_data</span></tt> and <tt class="docutils literal"><span class="pre">y_data</span></tt>, respectively.</p>
<p>We&#8217;ll start by generating and visualizing some data to get a better sense of the problem at hand:</p>
<div class="highlight-none"><div class="highlight"><pre># Set the random seed to get consistent data
srand(1)

# Number of examples to use
n = 100

# Specify the true value of the variable
true_coeffs = [2; -2; 0.5]

# Generate data
x_data = rand(n, 1) * 5
x_data_expanded = hcat([x_data .^ i for i in 1 : 3]...)
y_data = x_data_expanded * true_coeffs + 0.5 * rand(n, 1)


p = plot(
  x=x_data, y=y_data, Geom.point,
  Theme(panel_fill=color(&quot;white&quot;))
)
</pre></div>
</div>
<p>The following graph of the data will appear</p>
<img alt="_images/data.png" src="_images/data.png" />
<div class="section" id="linear-regression">
<h3>Linear Regression<a class="headerlink" href="#linear-regression" title="Permalink to this headline">¶</a></h3>
<p>We will first try to fit a line to the data. A general function for a line is</p>
<div class="math">
\[f(x) = \alpha + \beta x\]</div>
<p>where <span class="math">\(\alpha\)</span> is the offset and <span class="math">\(\beta\)</span> is the slope.
We would like to pick <span class="math">\(\alpha\)</span> and <span class="math">\(\beta\)</span> so that our data points lie &#8220;close&#8221; to
our line. For a point with coordinates <span class="math">\(x\)</span> and <span class="math">\(y\)</span> the residual between the point
and our line is defined as</p>
<div class="math">
\[r(x, y) = f(x) - y.\]</div>
<p>One reasonable way to measure the how different line is from the data is to
sum the squares of the residuals between each point in the data and the line:</p>
<div class="math">
\[E(\alpha, \beta) = \sum_{i = 1}^n (r(x_i, y_i))^2 = \sum_{i = 1}^n (\alpha + \beta x_i - y_i)^2.\]</div>
<p>We would like to choose <span class="math">\(\alpha\)</span> and <span class="math">\(\beta\)</span> to minimize this error.
We can now frame this problem in Julia code and solve our problem using LLS:</p>
<div class="highlight-none"><div class="highlight"><pre>slope = Variable()
offset = Variable()
line = offset + x_data * slope
residuals = line - y_data
fit_error = sum_squares(residuals)
optval = minimize!(fit_error)

# plot the data and the line
t = [0; 5; 0.1]
p = plot(
  layer(x=x_data, y=y_data, Geom.point),
  layer(x=t, y=evaluate(slope) * t + evaluate(offset), Geom.line),
  Theme(panel_fill=color(&quot;white&quot;))
)
</pre></div>
</div>
<p>The line of best fit on our data is shown below:</p>
<blockquote>
<div><img alt="_images/linear_regression.png" src="_images/linear_regression.png" />
</div></blockquote>
</div>
<div class="section" id="quadratic-regression">
<h3>Quadratic Regression<a class="headerlink" href="#quadratic-regression" title="Permalink to this headline">¶</a></h3>
<p>A line is probably not the best function to fit to this data. Instead, let&#8217;s try
to fit a quadratic function, which has the form:</p>
<div class="math">
\[f(x) = \alpha + \beta x + \gamma x ^ 2\]</div>
<p>where the new coefficient <span class="math">\(\gamma\)</span> corresponds to the quadratic term
A similar residual function from the linear regression example can be used here;
we measure the error of our quadratic fit by summing the squares of the
residuals</p>
<div class="math">
\[E(\alpha, \beta, \gamma) = \sum_{i = 1}^n (r(x_i, y_i))^2 = \sum_{i = 1}^n (\alpha + \beta x_i + \gamma x_i^2 - y_i)^2.\]</div>
<p>Again, we pick our coefficients to minimize the error.
Here is the Julia code to solve this problem using LLS and plot the quadratic:</p>
<div class="highlight-none"><div class="highlight"><pre>quadratic_coeff = Variable()
slope = Variable()
offset = Variable()
quadratic = offset + x_data * slope + quadratic_coeff * x_data .^ 2
residuals = quadratic - y_data
fit_error = sum_squares(residuals)
optval = minimize!(fit_error)

# Create some evenly spaced points for plotting, again replicate powers
t = reshape([0 : 0.1 : 5], length([0 : 0.1 : 5]), 1)
t_squared = t .^ 2

# Plot our regressed function
p = plot(
  layer(x=x_data, y=y_data, Geom.point),
  layer(x=t, y=evaluate(offset) + t * evaluate(slope) + t_squared * evaluate(quadratic_coeff), Geom.line),
  Theme(panel_fill=color(&quot;white&quot;))
)
</pre></div>
</div>
<img alt="_images/quadratic_regression.png" src="_images/quadratic_regression.png" />
<p>A much better fit than the line!</p>
</div>
</div>
<div class="section" id="control">
<h2>Control<a class="headerlink" href="#control" title="Permalink to this headline">¶</a></h2>
<p>A simple control problem on a system usually involves a variable <span class="math">\(x(t)\)</span>
that denotes the state of the system over time, and a variable <span class="math">\(u(t)\)</span> that
denotes the input into the system over time. Linear constraints are used to
capture the evolution of the system over time:</p>
<div class="math">
\[x(t) = Ax(t - 1) + Bu(t), \ \mbox{for} \ t = 1,\ldots, T,\]</div>
<p>where the numerical matrices <span class="math">\(A\)</span> and <span class="math">\(B\)</span> are called the dynamics and input matrices,
respectively.</p>
<p>The goal of the control problem is to find a sequence of inputs
<span class="math">\(u(t)\)</span> that will allow the state <span class="math">\(x(t)\)</span> to achieve specified values
at certain times. For example, we can specify initial and final states of the system:</p>
<div class="math">
\[\begin{split}\begin{align*}
  x(0) &amp;= x_i \\
  x(T) &amp;= x_f
\end{align*}\end{split}\]</div>
<p>Additional states between the initial and final states can also be specified. These
are known as waypoint constraints. Often, the input and state of the system will
have physical meaning, so we often want to find a sequence inputs that also
minimizes a least squares objective like the following:</p>
<div class="math">
\[\sum_{t = 0}^T \|Fx(t)\|^2_2 + \sum_{t = 1}^T\|Gu(t)\|^2_2,\]</div>
<p>where <span class="math">\(F\)</span> and <span class="math">\(G\)</span> are numerical matrices.</p>
<p>We&#8217;ll now apply the basic format of the control problem to an example of controlling
the motion of an object in a fluid over <span class="math">\(T\)</span> intervals, each of <span class="math">\(h\)</span> seconds.
The state of the system at time interval <span class="math">\(t\)</span> will be given by the position and the velocity of the
object, denoted <span class="math">\(p(t)\)</span> and <span class="math">\(v(t)\)</span>, while the input will be forces
applied to the object, denoted by <span class="math">\(f(t)\)</span>.
By the basic laws of physics, the relationship between force, velocity, and position
must satisfy:</p>
<div class="math">
\[\begin{split}\begin{align*}
  p(t+1) &amp;= p(t) + h v(t) \\
  v(t+1) &amp;= v(t) + h a(t)
\end{align*}.\end{split}\]</div>
<p>Here, <span class="math">\(a(t)\)</span> denotes the acceleration at time <span class="math">\(t\)</span>, for which we we use
<span class="math">\(a(t) = f(t) / m + g - d v(t)\)</span>,
where <span class="math">\(m\)</span>, <span class="math">\(d\)</span>, <span class="math">\(g\)</span> are constants for the mass of the object, the drag
coefficient of the fluid, and the acceleration from gravity, respectively.</p>
<p>Additionally, we have our initial/final position/velocity conditions:</p>
<div class="math">
\[\begin{split}\begin{align*}
  p(1) &amp;= p_i\\
  v(1) &amp;= v_i\\
  p(T+1) &amp;= p_f\\
  v(T+1) &amp;= 0
\end{align*}\end{split}\]</div>
<p>One reasonable objective to minimize would be</p>
<div class="math">
\[\mbox{objective} = \mu \sum_{t = 1}^{T+1} (v(t))^2 + \sum_{t = 1}^T (f(t))^2\]</div>
<p>We would like to keep both the forces small to perhaps save fuel, and keep
the velocities small for safety concerns.
Here <span class="math">\(\mu\)</span> serves as a parameter to control which part of the objective we
deem more important, keeping the velocity small or keeping the force small.</p>
<p>The following code builds and solves our control example:</p>
<div class="highlight-none"><div class="highlight"><pre># Some constraints on our motion
# The object should start from the origin, and end at rest
initial_velocity = [-20; 100]
final_position = [100; 100]

T = 100 # The number of timesteps
h = 0.1 # The time between time intervals
mass = 1 # Mass of object
drag = 0.1 # Drag on object
g = [0, -9.8] # Gravity on object

# Declare the variables we need
position = Variable(2, T)
velocity = Variable(2, T)
force = Variable(2, T - 1)

# Create a problem instance
mu = 1
constraints = []

# Add constraints on our variables
for i in 1 : T - 1
  constraints += position[:, i + 1] == position[:, i] + h * velocity[:, i]
end

for i in 1 : T - 1
  acceleration = force[:, i]/mass + g - drag * velocity[:, i]
  constraints += velocity[:, i + 1] == velocity[:, i] + h * acceleration
end

# Add position constraints
constraints += position[:, 1] == 0
constraints += position[:, T] == final_position

# Add velocity constraints
constraints += velocity[:, 1] == initial_velocity
constraints += velocity[:, T] == 0

# Solve the problem
optval = minimize!(sum_squares(force), constraints)
</pre></div>
</div>
<p>We can plot the trajectory taken by the object. The blue point denotes the initial
position, and the green point denotes the final position.</p>
<div class="highlight-none"><div class="highlight"><pre>pos = evaluate(position)
p = plot(
  layer(x=[pos[1, 1]], y=[pos[2, 1]], Geom.point, Theme(default_color=color(&quot;blue&quot;))),
  layer(x=[pos[1, T]], y=[pos[2, T]], Geom.point, Theme(default_color=color(&quot;green&quot;))),
  layer(x=pos[1, :], y=pos[2, :], Geom.line(preserve_order=true)),
  Theme(panel_fill=color(&quot;white&quot;))
)
</pre></div>
</div>
<img alt="_images/position.png" src="_images/position.png" />
<p>We can also see how the magnitude of the force changes over time.</p>
<div class="highlight-none"><div class="highlight"><pre>p = plot(x=1:T, y=sum(evaluate(force).^2, 1), Geom.line, Theme(panel_fill=color(&quot;white&quot;)))
</pre></div>
</div>
<img alt="_images/force.png" src="_images/force.png" />
</div>
<div class="section" id="image-processing">
<h2>Image Processing<a class="headerlink" href="#image-processing" title="Permalink to this headline">¶</a></h2>
<div class="section" id="tomography">
<h3>Tomography<a class="headerlink" href="#tomography" title="Permalink to this headline">¶</a></h3>
<p>Tomography is the process of reconstructing a density distribution from given
integrals over sections of the distribution. In our example, we will
work with tomography on black and white images.
Suppose <span class="math">\(x\)</span> be the vector of <span class="math">\(n\)</span> pixel densities, with <span class="math">\(x_j\)</span>
denoting how white pixel <span class="math">\(j\)</span> is.
Let <span class="math">\(y\)</span> be the vector of <span class="math">\(m\)</span> line integrals over the image, with <span class="math">\(y_i\)</span>
denoting the integral for line <span class="math">\(i\)</span>.
We can define a matrix <span class="math">\(A\)</span> to describe the geometry of the lines. Entry
<span class="math">\(A_{ij}\)</span> describes how much of pixel <span class="math">\(j\)</span> is intersected by line <span class="math">\(i\)</span>.
Assuming our measurements of the line integrals are perfect, we have the relationship that</p>
<div class="math">
\[y = Ax\]</div>
<p>However, anytime we have measurements, there are usually small errors that occur.
Therefore it makes sense to try to minimize</p>
<div class="math">
\[\|y - Ax\|_2^2.\]</div>
<p>This is simply an unconstrained least squares problem; something we can
readily solve in LLS!</p>
<div class="highlight-none"><div class="highlight"><pre>line_mat_x = readdlm(&quot;tux_sparse_x.txt&quot;)
line_mat_y = readdlm(&quot;tux_sparse_y.txt&quot;)
line_mat_val = readdlm(&quot;tux_sparse_val.txt&quot;)
line_vals = readdlm(&quot;tux_sparse_lines.txt&quot;)

# Form the sparse matrix from the data
# Image is 50 x 50
img_size = 50
# The number of pixels in the image
num_pixels = img_size * img_size

line_mat = spzeros(3300, num_pixels)

num_vals = length(line_mat_val)

for i in 1:num_vals
  x = int(line_mat_x[i])
  y = int(line_mat_y[i])
  line_mat[x + 1, y + 1] = line_mat_val[i]
end

x = Variable(num_pixels)
objective = sum_squares(line_mat * x - line_vals)
optval = minimize!(objective)

rows = zeros(img_size*img_size)
cols = zeros(img_size*img_size)
for i = 1:img_size
  for j = 1:img_size
    rows[(i-1)*img_size + j] = i
    cols[(i-1)*img_size + j] = img_size + 1 - j
  end
end

p = plot(
  x=rows, y=cols, color=reshape(evaluate(x), img_size, img_size), Geom.rectbin,
  Scale.ContinuousColorScale(Scale.lab_gradient(color(&quot;black&quot;), color(&quot;white&quot;)))
)
</pre></div>
</div>
<p>The final result of the tomography will look something like</p>
<img alt="_images/tomography.png" src="_images/tomography.png" />
</div>
</div>
<div class="section" id="machine-learning">
<h2>Machine Learning<a class="headerlink" href="#machine-learning" title="Permalink to this headline">¶</a></h2>
<div class="section" id="binary-classification">
<h3>Binary Classification<a class="headerlink" href="#binary-classification" title="Permalink to this headline">¶</a></h3>
<p>One common problem found in machine learning is the classification of a group of objects into two subgroups.
In this example, we will try to separate sports articles from
other texts in a collection of documents.</p>
<p>When classifying text documents, one of the most common techniques is to build
a term-by-document frequency matrix <span class="math">\(F\)</span>, where <span class="math">\(F_{ij}\)</span>
reflects the frequency of term <span class="math">\(j\)</span> in document <span class="math">\(i\)</span>.</p>
<p>The documents are then split into a training and testing set. For each document
in the training example, we also label the document with a label. In this case,
sports articles are labelled with a <span class="math">\(1\)</span> and all other text documents are
labelled with a <span class="math">\(-1\)</span>.
One reasonable approach to classify the documents is to model the label
as an affine function of the term frequencies of the document:</p>
<div class="math">
\[\mbox{label}(i) = v + \sum_{j = 1}^n w_jF_{ij}.\]</div>
<p>The goal now is to find a scalar <span class="math">\(v\)</span> and a weight vector <span class="math">\(w\)</span>, where <span class="math">\(w_j\)</span> reflects how
important term <span class="math">\(j\)</span> is in determining the label of the document. In our context, a positive value
means that the term is often seen in sports articles, while a negative value means
the term is often seen in the other documents. One reasonable approach to
finding the best <span class="math">\(w\)</span> and <span class="math">\(v\)</span> is to minimize the following objective:</p>
<div class="math">
\[\sum_{i = 1}^m  \left(\mbox{label}(i) - v - \sum_{j = 1}^n w_jF_{ij}\right)^2 + \lambda \sum_{j = 1}^n w_j^2\]</div>
<p>The first part of the objective is to ensure that our linear model actually closely
reproduces the labels of our training documents. The second part of the objective
ensures that the components of <span class="math">\(w\)</span> are relatively small.
Keeping <span class="math">\(w\)</span> small allows our model to behave better on documents not in the training set.
The regularization parameter <span class="math">\(\lambda\)</span>
is used to control how much we should prioritize keeping <span class="math">\(w\)</span> small versus
how close the affine function should fit the labels.</p>
<p>Here is the LLS code:</p>
<div class="highlight-none"><div class="highlight"><pre># read in the data
include(&quot;MatrixMarket.jl&quot;)
using MatrixMarket
A = full(MatrixMarket.mmread(&quot;largeCorpus.mtx&quot;))

# extract the classes of each document
classes = A[:,1]
# TODO: modify classes so that 4 5 6 are 1 2 3
classes[classes .&gt; 3] = classes[classes .&gt; 3] - 3
A = A[:, 2:end]

# split into train/test
numData = size(A, 1)
data = randperm(numData)
ind = floor(numData*0.7)
training = data[1:ind]
test = data[ind+1:end]
trainDocuments = A[training,:]
trainClasses = classes[training,:]
testDocuments = A[test,:]
testClasses = classes[test,:]

# change all other than sports to -1 (sports is 1)
holdClass = 1
trainClasses[trainClasses .!= holdClass] = -1
trainClasses[trainClasses .== holdClass] = 1
testClasses[testClasses .!= holdClass] = -1
testClasses[testClasses .== holdClass] = 1

# build the problem and solve with LLS
lambda = 100
w = Variable(size(A, 2))
v = Variable()
objective = sum_squares(trainDocuments * w + v - trainClasses) + lambda * sum_squares(w)
optval = minimize!(objective)
</pre></div>
</div>
<p>We can now sort our weight vector <span class="math">\(w\)</span> to see which words were the most
indicative of sports articles and which were most indicative of nonsports.</p>
<div class="highlight-none"><div class="highlight"><pre># print out the 5 words most indicative of sports and nonsports
words = String[]
f = open(&quot;largeCorpusfeatures.txt&quot;)
for i = 1:length(evaluate(w))
  push!(words, readline(f))
end
indices = sortperm(vec(evaluate(w)))
for i = 1:5
  print(words[indices[i]])
end
for i = 0:4
  print(words[indices[length(words) - i]])
end
</pre></div>
</div>
<p>Each run will yield different words, but it&#8217;ll be clear which words
come from sports articles.</p>
</div>
</div>
<div class="section" id="time-series-analysis">
<h2>Time Series Analysis<a class="headerlink" href="#time-series-analysis" title="Permalink to this headline">¶</a></h2>
<p>A time series is a sequence of data points, each associated with a time.
In our example, we will work with a time series of daily
temperatures in the city of Melbourne, Australia over a period of a few years.
Let <span class="math">\(x\)</span> be the vector of the time series, and <span class="math">\(x_i\)</span> denote
the temperature in Melbourne on day <span class="math">\(i\)</span>.
Here is a picture of the time series:</p>
<img alt="_images/melbourne.png" src="_images/melbourne.png" />
<p>We can quickly compute the mean of the time series to be <span class="math">\(11.2\)</span>. If
we were to always guess the mean as the temperature of Melbourne on a given day,
the RMS error of our guesswork would be <span class="math">\(4.1\)</span>. We&#8217;ll try to lower
this RMS error by coming up with better ways to model the temperature than
guessing the mean.</p>
<p>A simple way to model this time series would be to find a smooth curve that
approximates the yearly ups and downs.
We can represent this model as a vector <span class="math">\(s\)</span> where <span class="math">\(s_i\)</span>
denotes the temperature on the <span class="math">\(i\)</span>-th day.
To force this trend to repeat yearly, we simply want</p>
<div class="math">
\[s_i = s_{i + 365}\]</div>
<p>for each applicable <span class="math">\(i\)</span>.</p>
<p>We also want our model to have two more properties. The first is that
the temperature on each day in our model should be relatively close to the actual temperature of that day.
The second is that our model needs to be smooth, so the change in temperature from day to
day should be relatively small. The following objective would capture both properties:</p>
<div class="math">
\[\sum_{i = 1}^n (s_i - x_i)^2 + \lambda \sum_{i = 2}^n(s_i - s_{i - 1})^2\]</div>
<p>where <span class="math">\(\lambda\)</span> is the smoothing parameter. The larger <span class="math">\(\lambda\)</span> is,
the smoother our model will be.</p>
<p>The following code uses LLS to find and plot the model:</p>
<div class="highlight-none"><div class="highlight"><pre>temps = readdlm(&quot;melbourne_temps.txt&quot;, &#39;,&#39;)
n = size(temps)[1]
p = plot(
  x=1:1500, y=temps[1:1500], Geom.line,
  Theme(panel_fill=color(&quot;white&quot;))
)
# draw(PNG(&quot;melbourne.png&quot;, 16cm, 12cm), p)

yearly = Variable(n)
eq_constraints = []
for i in 365 + 1 : n
  eq_constraints += yearly[i] == yearly[i - 365]
end

smoothing = 100
smooth_objective = sum_squares(yearly[1 : n - 1] - yearly[2 : n])
optval = minimize!(sum_squares(temps - yearly) + smoothing * smooth_objective, eq_constraints)
residuals = temps - evaluate(yearly)

# Plot smooth fit
p = plot(
  layer(x=1:1500, y=evaluate(yearly)[1:1500], Geom.line, Theme(default_color=color(&quot;red&quot;), line_width=2px)),
  layer(x=1:1500, y=temps[1:1500], Geom.line),
  Theme(panel_fill=color(&quot;white&quot;))
)
</pre></div>
</div>
<img alt="_images/yearly_fit.png" src="_images/yearly_fit.png" />
<p>We can also plot the residual temperatures, <span class="math">\(r\)</span>, define as <span class="math">\(r = x - s\)</span>.</p>
<div class="highlight-none"><div class="highlight"><pre># Plot residuals for a few days
p = plot(
  x=1:100, y=residuals[1:100], Geom.line,
  Theme(default_color=color(&quot;green&quot;), panel_fill=color(&quot;white&quot;))
)
</pre></div>
</div>
<img alt="_images/residuals.png" src="_images/residuals.png" />
<p>Our smooth model has a RMS error of <span class="math">\(2.7\)</span>, a significant improvement from
just guessing the mean, but we can do better.</p>
<p>We now make the hypothesis that the residual temperature on a given day is
some linear combination of the previous <span class="math">\(5\)</span> days. Such a model is called
autoregressive. We are essentially trying to fit the residuals
as a function of other parts of the data itself.
We want to find a vector of coefficients <span class="math">\(a\)</span> such that</p>
<div class="math">
\[\mbox{r}(i) \approx \sum_{j = 1}^5 a_j \mbox{r}(i - j)\]</div>
<p>This can be done by simply minimizing the following sum of squares objective</p>
<div class="math">
\[\sum_{i = 6}^n \left(\mbox{r}(i) - \sum_{j = 1}^5 a_j \mbox{r}(i - j)\right)^2\]</div>
<p>The following LLS code solves this problem and plots our autoregressive model
against the actual residual temperatures:</p>
<div class="highlight-none"><div class="highlight"><pre># Generate the residuals matrix
ar_len = 5
residuals_mat = residuals[ar_len : n - 1]
for i = 1:ar_len - 1
  residuals_mat = [residuals_mat residuals[ar_len - i : n - i - 1]]
end

# Solve autoregressive problem
ar_coef = Variable(ar_len)
optval2 = minimize!(sum_squares(residuals_mat * ar_coef - residuals[ar_len + 1 : end]))

# plot autoregressive fit of daily fluctuations for a few days
ar_range = 1:145
day_range = ar_range + ar_len
p = plot(
  layer(x=day_range, y=residuals[day_range], Geom.line, Theme(default_color=color(&quot;green&quot;))),
  layer(x=day_range, y=residuals_mat[ar_range, :] * evaluate(ar_coef), Geom.line, Theme(default_color=color(&quot;red&quot;))),
  Theme(panel_fill=color(&quot;white&quot;))
)
</pre></div>
</div>
<img alt="_images/ar_fit.png" src="_images/ar_fit.png" />
<p>Now, we can add our autoregressive model for the residual temperatures to our
smooth model to get an better fitting model for the daily temperatures in the city of
Melbourne:</p>
<div class="highlight-none"><div class="highlight"><pre>total_estimate = evaluate(yearly)
total_estimate[ar_len + 1 : end] += residuals_mat * evaluate(ar_coef)

# plot final fit of data
p = plot(
  layer(x=1:1500, y=total_estimate[1:1500], Geom.line, Theme(default_color=color(&quot;red&quot;))),
  layer(x=1:1500, y=temps[1:1500], Geom.line),
  Theme(panel_fill=color(&quot;white&quot;))
)
</pre></div>
</div>
<img alt="_images/total_fit.png" src="_images/total_fit.png" />
<p>The RMS error of this final model is <span class="math">\(2.3\)</span>.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">LineaLeastSquares.jl Examples</a><ul>
<li><a class="reference internal" href="#regression">Regression</a><ul>
<li><a class="reference internal" href="#linear-regression">Linear Regression</a></li>
<li><a class="reference internal" href="#quadratic-regression">Quadratic Regression</a></li>
</ul>
</li>
<li><a class="reference internal" href="#control">Control</a></li>
<li><a class="reference internal" href="#image-processing">Image Processing</a><ul>
<li><a class="reference internal" href="#tomography">Tomography</a></li>
</ul>
</li>
<li><a class="reference internal" href="#machine-learning">Machine Learning</a><ul>
<li><a class="reference internal" href="#binary-classification">Binary Classification</a></li>
</ul>
</li>
<li><a class="reference internal" href="#time-series-analysis">Time Series Analysis</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="julia_tutorial.html"
                        title="previous chapter">LinearLeastSquares.jl Tutorial</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="credits.html"
                        title="next chapter">Credits</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/julia_examples.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="credits.html" title="Credits"
             >next</a> |</li>
        <li class="right" >
          <a href="julia_tutorial.html" title="LinearLeastSquares.jl Tutorial"
             >previous</a> |</li>
        <li><a href="index.html">LLS 0.1 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2014, David Zeng, Keegan Go, Karanveer Mohan.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>